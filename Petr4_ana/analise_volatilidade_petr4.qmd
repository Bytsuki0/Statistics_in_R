---
title: "Análise de Volatilidade Estocástica e Retornos Intradiários - PETR4"
author: "Gustavo Vitor da Silva"
format: html
editor: visual
---

## Introdução

Este relatório explora o comportamento da volatilidade e dos retornos da ação PETR4 ao longo de 2021, com dados de frequência de 1 minuto extraídos da plataforma MetaTrader. Utilizamos modelos de volatilidade estocástica via `stochvol`, comparações com volatilidade realizada, e examinamos propriedades de clustering de volatilidade.

## Leitura e Pré-processamento dos Dados

-   Remoção de janelas de abertura com menor liquidez (10:00 até 10:20) e dos últimos minutos de pregão (após 16:55).
-   Exclusão do feriado em 17/02/2021.
-   Conversão para série temporal (`xts`) e remoção de outliers extremos substituindo-os pela observação anterior.

```{r load-packages, include=FALSE}
  library(dplyr)
  library(ggplot2)
  library(tidyr)
  library(zoo)
  library(xts)
  library(forecast)
  library(lubridate)
  library(PerformanceAnalytics)
  library(highfrequency)         
  library(quantmod)    
  library(tseries)     
  library(FinTS)       
  library(stochvol)  
  library(fpp2)     
  library(fpp3)       
  #library(modeltime)    
  #library(timetk)      
  library(parsnip)      
  library(rsample)      
  library(cowplot)
```

```{r}
os <- Sys.info()["sysname"]
if(os == "Windows") {
  dt.intra <- read.csv("D:/Code/R_studio/Petr4_ana/dt_1min_PETR4_2021_metatrader.csv", 
                       header = TRUE, stringsAsFactors = FALSE, 
                       sep = ";", dec = ",")
} else if(os == "Linux") {
  dt.intra <- read.csv("~/Documentos/Coding/Statistics_in_R/Petr4_ana/dt_1min_PETR4_2021_metatrader.csv", 
                       header = TRUE, stringsAsFactors = FALSE, 
                       sep = ";", dec = ",")
}

dt1 <- as_tibble(dt.intra) %>% 
  mutate(Period = ymd_hms(X)) %>%
  select(-X) %>% 
  filter(!(hour(Period) == 10 & minute(Period) < 20)) %>% 
  filter(hour(Period) < 17) %>% 
  filter(!(hour(Period) == 16 & minute(Period) > 54)) %>% 
  filter(!(date(Period) == "2021-02-17")) %>% 
  arrange(Period)

ret.1min <- as.xts(dt1$Ret.1min, order.by = dt1$Period)

```

## Observação inicial

```{r}
plot(ret.1min, main="PETR4 Retornos 1min", col="black")
boxplot(as.double(ret.1min), main="Boxplot dos Retornos 1min")
```

## Identificação e remoçãode Outliers

Observamos os Outliers presentes nos valores maximos e minimos dos retornos. Com isso os removemos observamos novamente os gráficos de boxplot e a série temporal.

```{r}
warning=FALSE
message=FALSE
# Teste ADF e visualizações iniciais
par(mfrow=c(1,1))

# Identificar outliers
idx_min <- which.min(as.double(ret.1min))
idx_max <- which.max(as.double(ret.1min))

# Substituir outliers pela observação anterior
ret.1min[idx_min] <- ret.1min[idx_min - 1]
ret.1min[idx_max] <- ret.1min[idx_max - 1]

plot.ts(ret.1min)
boxplot(as.double(ret.1min))

```

## Testes de Estacionariedade

```{r}
tseries::adf.test(ret.1min)
```

Resultado mostra que os retornos são estacionários, o que é esperado para séries de retornos.

## Analises de têndencias pré e pós queda

```{r}

  dados_xts <- xts(dt1[, c("Close.1min", "Ret.1min")], order.by = dt1$Period)
  
  idx_min <- which.min(as.double(ret.1min))
  idx_max <- which.max(as.double(ret.1min))
  
  dados_xts[idx_min] <- dados_xts[idx_min - 1]
  dados_xts[idx_max] <- dados_xts[idx_max - 1]
  p2 = idx_min +10000
```

```{r}
dados_xts$LogRet.1min <- log(1 + dados_xts$Ret.1min)

dados_xts <- na.omit(dados_xts)

calc_volatilidade_historica <- function(retornos, janela = 21) {
  vol_hist <- rollapply(retornos, width = janela, 
                        FUN = function(x) sd(x, na.rm = TRUE), 
                        by.column = TRUE, 
                        align = "right")
  return(vol_hist)
}

dados_xts$Vol_Hist_30min <- calc_volatilidade_historica(dados_xts$LogRet.1min, janela = 30)

minutos_ano <- 252 * 390
dados_xts$Vol_Anual <- dados_xts$Vol_Hist_30min * sqrt(minutos_ano)

volhist30min=dados_xts$Vol_Hist_30min

plot(volhist30min[1:10000], main = "Volatilidade (Janela 30 min) Pré queda", xlab = "Data", ylab = "Volatilidade")

plot(volhist30min[idx_min:p2], main = "Volatilidade (Janela 30 min) Pós queda", xlab = "Data", ylab = "Volatilidade")
```

```{r}
warning=FALSE
message=FALSE
log_ret_vec <- as.numeric(dados_xts$LogRet.1min)
ret_vec <- as.numeric(dados_xts$Ret.1min)

#adf_test <- adf.test(log_ret_vec)
#print("Teste ADF para Log-Retornos:")
#print(adf_test)
#kpss_test <- kpss.test(log_ret_vec)
#print("Teste KPSS para Log-Retornos:")
#print(kpss_test)

# Visualizando ACF e PACF
par(mfrow = c(1, 2))
acf(log_ret_vec[1:10000], main = "ACF - Log-Retornos Pré queda", na.action = na.pass)
pacf(log_ret_vec[1:10000], main = "PACF - Log-Retornos Pré queda", na.action = na.pass)

par(mfrow = c(1, 2))
acf(log_ret_vec[idx_min:p2], main = "ACF - Log-Retornos Pós queda", na.action = na.pass)
pacf(log_ret_vec[idx_min:p2], main = "PACF - Log-Retornos Pós queda", na.action = na.pass)
```

## Ajuste do Modelo de Volatilidade Estocástica

Ajustamos um modelo `svsample()` a dois blocos temporais:

1.  Primeiros 10000 pontos antes do maior retorno absoluto negativo.
2.  10000 pontos após o maior retorno (queda abrupta) para comparar regimes.

```{r setup, include=FALSE}
echo=FALSE
warning=FALSE
message=FALSE

set.seed(123)
ret_vec <- as.numeric(ret.1min[1:10000])
sv_fit <- svsample(ret_vec, draws = 10000, burnin = 1000)

max = idx_max+10000
ret_vec2 <- as.numeric(ret.1min[idx_max:max])
sv_fit2 <- svsample(ret_vec2, draws = 10000, burnin = 1000)

```

```{r}
plot(sv_fit, showobs = FALSE)
title(main = "Pré queda")
plot(sv_fit2, showobs = FALSE)
title(main = "Pós queda")
```

Analisando os dados pós e pré queda da bolsa podemos ver uma mudança principalmente nas distribuições normais de Mu, Phi e Sigma, onde podemos definir o que cada variavel nos diz como:

### Interpretação de μ (mu)

1.  **Média de longo prazo**

    -   **μ** define o valor médio ao qual Log-volatilidade reverte em longo prazo.

    -   Processos com μ maior indicam que, em média, a volatilidade tende a ficar mais elevada.

2.  **“Drift” da volatilidade latente**

    -   Atua como termo constante que “puxa” o nível de volatilidade de volta ao seu ponto de equilíbrio

    -   Ao estimar o modelo, a média pontual de μ na distribuição posterior corresponde à média aritmética.

### Interpretação de φ (phi)

1.  **Persistência (autoregressão)**

    -   **φ** atua como coeficiente AR(1) medindo a “memória” da volatilidade.

    -   Se φ≈1, choques em ht−1 têm efeito duradouro​, resultando em **clusters de volatilidade**.

    **Estacionaridade**

    -   O modelo é estacionário somente se ∣ϕ∣\<1; valores absolutos acima quebram a estabilidade do processo latente.

    -   Estimações típicas em mercados emergentes mostram φ entre 0.95 e 0.99, indicando alta persistência.

### Interpretação de σ (sigma)

1.  **Volatilidade da volatilidade**

    -   **σ** é o desvio-padrão dos choques que afetam o processo de log-volatilidade

    -   Quanto maior σ, mais pronunciadas são as flutuações de curto prazo na volatilidade.

2.  **Incerteza dinâmica**

    -   Reflete a variabilidade intrínseca na evolução da volatilidade latente, controlando a rapidez das mudanças de regimes.

    -   Modelos com σ elevado tendem a capturar melhor eventos extremos (*fat tails*) e mudanças bruscas no risco.

### O que podemos retirar das nossas observações

Após a grande queda observada em PETR4, estimamos um modelo de volatilidade estocástica usando 10 000 observações subsequentes e constatamos que as distribuições a posteriori de **σ** (volatilidade da volatilidade) e **φ** (persistência) tornaram-se **menos concentradas** em torno dos valores médios pré-queda. Isso evidencia que, no regime pós-choque, há **maior incerteza** sobre (a) quão rapidamente a volatilidade reverte ao seu nível de equilíbrio e (b) a magnitude dos choques na volatilidade latente.

### 1. Implicações de φ menos concentrado

1.  **Menor certeza sobre a persistência**\
    Um φ com distribuição mais ampla indica que não há confiança clara de que choques passados em (h_t) continuem a influenciar fortemente o nível futuro de volatilidade.

2.  **Regime de volatilidade transitória**\
    A dispersão elevada sinaliza possível transição entre regimes de volatilidade — desta forma, o “memory effect” do processo se torna imprevisível.

3.  **Previsões de risco mais amplas**\
    Forecasts de intervalos dinâmicos (e.g. VaR) baseados em φ incerto geram bandas de confiança mais largas, refletindo menor segurança na persistência futura.

### 2. Implicações de σ menos concentrado

1.  **Volatilidade da volatilidade incerta**\
    Uma σ com posterior mais dispersa revela incerteza na magnitude dos choques em (h_t), sugerindo que picos de volatilidade podem ser muito mais extremos ou moderados do que o modelo pré-queda sugeria.

2.  **Riscos extremos imprevisíveis**\
    Como σ controla a variabilidade dos próprios choques de volatilidade, sua dispersão aumenta a probabilidade de eventos de cauda (*tail events*) inesperados.

3.  **Necessidade de hedge robusto**\
    Para mitigar risco, adota-se hedge que contemple cenários de volatilidade superior ao patamar pré-queda, dada a incerteza elevada em σ.

## 3. Interpretações Combinadas

-   **Pós-Queda: mais volátil e menos persistente**\
    A conjugação de φ incerto e σ incerto sugere um mercado onde a volatilidade oscila abruptamente com memória curta, indicando potencial benefício de modelos de *regime-switching* ou de volatilidade local.

## Comparação com Volatilidade Realizada

```{r}
df_vol <- data.frame(volatility = sv_fit[["latent0"]][[1]])
sv_vol_mean <- exp(df_vol / 2)
vol_xts <- xts(sv_vol_mean, order.by = dt1$Period[1:5000])
realized_vol <- rollapply(ret.1min[1:5000]^2, width=30, FUN=function(x) sqrt(252*390*mean(x)), by.column=TRUE, align="right")
realized_vol <- na.omit(realized_vol)
```

```{r}
par(mfrow=c(2,1))
plot(realized_vol, main="Volatilidade Realizada")
plot(vol_xts, main="Volatilidade Estocástica Estimada")
```

**Insight:** Ambas as volatilidades capturam padrões semelhantes, porém a volatilidade estocástica suaviza ruídos de alta frequência, sendo mais adequada para modelagem de risco e precificação.

## Cluster de Volatilidade

```{r}
acf(abs(ret_vec), main="ACF dos Retornos Absolutos")
pacf(abs(ret_vec), main="PACF dos Retornos Absolutos")
```

**Insight:** Forte autocorrelação nos retornos absolutos indica *clusteres de volatilidade*, fenômeno típico em séries financeiras.

## Teste ARCH LM

```{r}
ArchTest(ret_vec, lags = 10)
```

**Resultado:** Significativo — indicando presença de heterocedasticidade condicional.

## Distribuições Posteriores dos Parâmetros

```{r}
echo=FALSE
warning=FALSE
message=FALSE

params_mat <- as.matrix(sv_fit$para)
params_df <- as_tibble(params_mat)
params_df <- params_df %>% select(-any_of(c("nu", "rho")))  


params_mat2 <- as.matrix(sv_fit2$para)
params_df2 <- as_tibble(params_mat2)
params_df2 <- params_df2 %>% select(-any_of(c("nu", "rho")))  


df_long <- pivot_longer(params_df, cols = everything(),
                         names_to = "param", values_to = "value")


df_long2 <- pivot_longer(params_df2, cols = everything(),
                        names_to = "param", values_to = "value")
```

```{r}
ggplot(df_long, aes(x = value)) +
  geom_histogram(bins = 50) +
  facet_wrap(~param, scales = "free") +
  labs(title = "Distribuições dos Parâmetros pré queda",
      x = "Valor", y = "Frequência") +
  theme_minimal()

```

```{r}

ggplot(df_long2, aes(x = value)) +
  geom_histogram(bins = 50) +
  facet_wrap(~param, scales = "free") +
  labs(title = "Distribuições dos Parâmetros pós queda",
      x = "Valor", y = "Frequência") +
  theme_minimal()
```

**Interpretação:**

-   `mu`: Média dos log-retornos.
-   `phi`: Persistência da volatilidade — valores próximos de 1 indicam alta persistência.
-   `sigma`: Volatilidade da volatilidade — mostra o quanto a variância latente oscila.

## Comparação Antes e Depois da Queda

Parâmetros do modelo após a queda indicam aumento em `sigma` e possível redução em `phi`, sugerindo maior instabilidade e menor persistência da volatilidade.

## Próximos Passos

-   Testar modelos com distribuição `t` para capturar caudas mais pesadas.
-   Incorporar covariáveis exógenas como volume, notícias ou macrodados.
-   Comparar com modelos GARCH para benchmarking.
